{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtt0iB5Pb/U1/h2zYEtrz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaoSunny124/AI_201/blob/main/Langchain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r15-IzT7Df3R",
        "outputId": "63ad23af-d7f1-42ef-b832-a910fd986ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-pinecone langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pinecone_api_key = userdata.get('Pinecone_Api_Key')\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n"
      ],
      "metadata": {
        "id": "rIkgegGODrwF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"practise-rag\"\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric='cosine',\n",
        "    spec  = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)\n",
        ""
      ],
      "metadata": {
        "id": "mR6xsncXD7b6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"My_chatbot\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\", google_api_key = GEMINI_KEY)"
      ],
      "metadata": {
        "id": "SCGKoR_cEBVh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Thanks To Allah 7th Time run\")"
      ],
      "metadata": {
        "id": "56LNv_vpEQop"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R-k9VRxEVIp",
        "outputId": "0ed29773-1819-4785-b65e-b2c16b846f59"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021536385640501976,\n",
              " -0.008258498273789883,\n",
              " -0.024666937068104744,\n",
              " -0.007488536648452282,\n",
              " 0.03480295464396477,\n",
              " -0.010281002148985863,\n",
              " 0.04205457493662834,\n",
              " -0.02350606396794319,\n",
              " 0.025906207039952278,\n",
              " 0.025753257796168327]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "6pPFtMbSEdNm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"Agentic AI is becoming increasingly important in industries like autonomous vehicles, robotics, and smart cities, where real-time decision-making and adaptability are crucial for success.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Industry Applications\", \"industries\": [\"Autonomous Vehicles\", \"Robotics\", \"Smart Cities\"]}\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"LangChain is a framework for building applications with LLMs (Large Language Models), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Framework\"}\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"The use of AI in healthcare is growing rapidly. Recent advancements in diagnostic AI tools are helping doctors identify diseases more accurately and faster, significantly improving patient outcomes.\",\n",
        "    metadata={\"topic\": \"Healthcare AI\", \"category\": \"Medical Technology\", \"impact\": \"Positive\"}\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"In the latest world news, a new tech company has developed an innovative AI that is able to solve real-world problems faster than previous models, pushing the boundaries of automation and efficiency.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"date\": \"2025-01-02\", \"company\": \"Innovative AI Company\"}\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Artificial Intelligence\", \"importance\": \"High\"}\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"LangChain offers a wide range of tools to work with LLMs. This includes support for document search, question-answering systems, and memory management to make intelligent agents more effective in real-world tasks.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Tools\", \"use_case\": \"Advanced workflows\"}\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"I have chocolate chip pancake and scrambled eggs for breakfast\",\n",
        "    metadata={\"source\": \"personal\", \"meal\": \"breakfast\"}\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"A new world record has been set for the fastest internet speed, with researchers breaking through previous limitations using advanced fiber-optic technology, promising faster and more efficient global communication.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"category\": \"Innovation\", \"record\": \"Fastest Internet Speed\", \"date\": \"2025-01-02\"}\n",
        ")\n",
        "documents = [\n",
        "    document_1, document_2, document_3, document_4, document_5,\n",
        "    document_6, document_7, document_8, document_9, document_10\n",
        "]"
      ],
      "metadata": {
        "id": "y8Ij1ks1Exwu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(  documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU8DQcuVFyGp",
        "outputId": "c370ed7d-9c71-45e9-9b6c-714621703a9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqt23cqnF1YS",
        "outputId": "5ef1b3a0-8236-49a7-fea0-be3af0ab5feb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('cdbbe628-1d83-46ec-a5dc-74ffa49c768a')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for i in range (len(documents))]\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VZUjVuhGLxr",
        "outputId": "060f4267-2902-44d7-8fb4-23fab515ed60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['4b96149f-ab94-4636-a808-4bb95d0b50bd',\n",
              " '6142b645-678a-46a7-b23c-53c888ac15e9',\n",
              " '67c10977-0793-4d54-8e4d-be1826bc60b7',\n",
              " 'f08956e0-5745-426d-9bb4-b78b2f0b7138',\n",
              " '9c44d43c-5b2d-4436-8c04-203045d7f8e2',\n",
              " '33d145fb-9a03-48a8-a30d-68e4ce72c442',\n",
              " 'a9fb95f7-fde9-4820-afd4-4bab735a26b4',\n",
              " '4156db6f-1903-44bd-bcb3-07c8be354a0c',\n",
              " '3f3dcfdf-b0e4-41d1-b4b2-cfa6c79c1087',\n",
              " 'ee6d3036-3b82-4c53-b669-7fd23794b2c3']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_result = vector_store.similarity_search(\n",
        "    \"What is agentic AI?\", k=7\n",
        ")\n",
        "print(vector_result[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NydEF3BKGOoO",
        "outputId": "f2a9bdfd-cd34-4056-f6f8-7a94242e13ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def user_answer(question):\n",
        "\n",
        "  vector_result = vector_store.similarity_search(question, k=5)\n",
        "  from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "  from langchain.prompts import PromptTemplate\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(\n",
        "      api_key=GEMINI_KEY,\n",
        "      model = \"gemini-2.0-flash-exp\",\n",
        "      max_tokens= 100,\n",
        "      temperature=0.7\n",
        "  )\n",
        "\n",
        "  prompt1= PromptTemplate(\n",
        "      input_variables=[\"question\"],\n",
        "      template = \"Using this data {vector_result} . Answer the following question: \\n\\n{question}\"\n",
        "  )\n",
        "  chain1= prompt1 | llm\n",
        "\n",
        "  final_answer = chain1.invoke({\"vector_result\": vector_result, \"question\": question})\n",
        "\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "s_XLaaFyGRZZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = user_answer(\"What's the latest news?\")"
      ],
      "metadata": {
        "id": "d1ehD56hGVEp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "CT3odGxQGXXg",
        "outputId": "0ae627b7-e4a4-4674-cf51-2e3a3838bf45"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided data, here's a summary of the latest news:\n\n*   **Innovative AI:** A new tech company has developed an innovative AI that solves real-world problems faster than previous models. This is pushing the boundaries of automation and efficiency.\n*   **Fastest Internet Speed:** A new world record has been set for the fastest internet speed using advanced fiber-optic technology.\n*   **AI in Customer Service:** AI-powered chatbots have been shown to outperform human"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_1 = user_answer(\"What is Langchain and where it is used ?\")"
      ],
      "metadata": {
        "id": "tX0nfvh6Ha3D"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response_1.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "DWNGdRlDHdzI",
        "outputId": "86517ea7-cbde-44ac-d766-740c59734bda"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided documents, here's an answer to your question:\n\n**What is LangChain?**\n\nLangChain is a framework designed to help build applications using Large Language Models (LLMs) like GPT. It provides tools for managing chains of operations, creating agents, and handling memory within these applications. Essentially, it helps developers create more advanced AI applications using LLMs.\n\n**Where is LangChain used?**\n\nLangChain is used in a variety of ways, including:"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2 = user_answer(\"What i like in breakfast , Tell me in Key points\")"
      ],
      "metadata": {
        "id": "XWbeHhiSHgTr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response_2.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "uBEduxgVHikq",
        "outputId": "e2cf0a10-0939-4932-bd96-6c059b2162c7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, based on the provided data, here's what we can extract about your breakfast preferences in key points:\n\n*   **Chocolate chip pancake:** You enjoy chocolate chip pancakes.\n*   **Scrambled eggs:** You also like to have scrambled eggs for breakfast.\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}